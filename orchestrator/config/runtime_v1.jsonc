{
  // Centralized model/runtime defaults used by the orchestrator.
  // NOTE: Environment variables override these (see .env.example).

  // ---------------------------
  // Model + generation controls
  // ---------------------------
  "model": "gpt-4o-mini",           // default model (can override via OPENAI_MODEL)
  "temperature": 0,                  // deterministic extraction
  "max_output_tokens": 2000,         // keep outputs bounded

  // ---------------------------
  // Networking / timeouts
  // ---------------------------
  "timeout_seconds": 120,            // per-request network timeout

  // ---------------------------
  // Notes
  // ---------------------------
  "notes": "Values here are informational; the OpenAI client reads env overrides first. Keep this in repo; never commit real secrets."
}
